{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, save_model, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "batch_size = 128\n",
    "nb_epoch = 10\n",
    "\n",
    "# Parameters for MNIST dataset\n",
    "nb_classes = 10\n",
    "\n",
    "# Parameters for MLP\n",
    "prob_drop_input = 0.2               # drop probability for dropout @ input layer\n",
    "prob_drop_hidden = 0.5              # drop probability for dropout @ fc layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "Y_Train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_Test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gpu\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\gpu\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense1 (Dense)               (None, 625)               490625    \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 625)               391250    \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense3 (Dense)               (None, 10)                6260      \n",
      "=================================================================\n",
      "Total params: 888,135\n",
      "Trainable params: 888,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpu\\Anaconda3\\envs\\keras\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=784, activation=\"sigmoid\", name=\"dense1\", units=625, kernel_initializer=\"normal\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\gpu\\Anaconda3\\envs\\keras\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=625, activation=\"sigmoid\", name=\"dense2\", units=625, kernel_initializer=\"normal\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\gpu\\Anaconda3\\envs\\keras\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=625, activation=\"softmax\", name=\"dense3\", units=10, kernel_initializer=\"normal\")`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Multilayer Perceptron model\n",
    "model = Sequential()\n",
    "model.add(Dense(output_dim=625, input_dim=784, init='normal', activation='sigmoid', name='dense1'))\n",
    "model.add(Dropout(prob_drop_input, name='dropout1'))\n",
    "model.add(Dense(output_dim=625, input_dim=625, init='normal', activation='sigmoid', name='dense2'))\n",
    "model.add(Dropout(prob_drop_hidden, name='dropout2'))\n",
    "model.add(Dense(output_dim=10, input_dim=625, init='normal', activation='softmax', name='dense3'))\n",
    "model.compile(optimizer=RMSprop(lr=0.001, rho=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " 2944/60000 [>.............................] - ETA: 3s - loss: 0.2676 - acc: 0.9127"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpu\\Anaconda3\\envs\\keras\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2480 - acc: 0.9244 - val_loss: 0.1794 - val_acc: 0.9448\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1790 - acc: 0.9446 - val_loss: 0.1388 - val_acc: 0.9582\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1419 - acc: 0.9561 - val_loss: 0.1116 - val_acc: 0.9653\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1194 - acc: 0.9636 - val_loss: 0.0964 - val_acc: 0.9698\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1019 - acc: 0.9691 - val_loss: 0.0897 - val_acc: 0.9712\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0895 - acc: 0.9726 - val_loss: 0.0850 - val_acc: 0.9738\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0801 - acc: 0.9756 - val_loss: 0.0777 - val_acc: 0.9760\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.0723 - acc: 0.9777 - val_loss: 0.0763 - val_acc: 0.9765\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0642 - acc: 0.9797 - val_loss: 0.0699 - val_acc: 0.9795\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0600 - acc: 0.9810 - val_loss: 0.0704 - val_acc: 0.9786\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "save_model(model, './model/model_mlp')\n",
    "checkpoint = ModelCheckpoint(filepath='./model/weights.epoch.{epoch:02d}-val_loss.{val_loss:.2f}.hdf5', verbose=0)\n",
    "history = model.fit(X_train, Y_Train, nb_epoch=nb_epoch, batch_size=batch_size, verbose=1,\n",
    "                    callbacks=[checkpoint], validation_data=(X_test, Y_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 81us/step\n",
      "\n",
      "Summary: Loss over the test dataset: 0.07, Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "evaluation = model.evaluate(X_test, Y_Test, verbose=1)\n",
    "print('\\nSummary: Loss over the test dataset: %.2f, Accuracy: %.2f' % (evaluation[0], evaluation[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense1 (Dense)               (None, 625)               490625    \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 625)               391250    \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense3 (Dense)               (None, 10)                6260      \n",
      "=================================================================\n",
      "Total params: 888,135\n",
      "Trainable params: 888,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Restore trained model\n",
    "loaded_model = load_model('./model/model_mlp')\n",
    "loaded_model.load_weights('./model/weights.epoch.09-val_loss.0.07.hdf5')\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 75us/step\n",
      "\n",
      "Summary: Loss over the test dataset: 0.07, Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with loaded model\n",
    "evaluation = loaded_model.evaluate(X_test, Y_Test, verbose=1)\n",
    "print('\\nSummary: Loss over the test dataset: %.2f, Accuracy: %.2f' % (evaluation[0], evaluation[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
